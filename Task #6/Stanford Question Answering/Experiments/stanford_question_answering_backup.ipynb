{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":799923,"sourceType":"datasetVersion","datasetId":374}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"3c56a31d8e6b32d","cell_type":"markdown","source":"# Importing Required Libraries","metadata":{}},{"id":"initial_id","cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nimport tensorflow as tf\nfrom datasets import Dataset, DatasetDict\nfrom transformers import create_optimizer\nfrom transformers.keras_callbacks import PushToHubCallback\nfrom transformers import AutoTokenizer, TFAutoModelForQuestionAnswering\nimport json","metadata":{"ExecuteTime":{"end_time":"2025-08-21T15:52:21.411243Z","start_time":"2025-08-21T15:51:33.223816Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T01:03:51.007877Z","iopub.execute_input":"2025-08-22T01:03:51.008145Z","iopub.status.idle":"2025-08-22T01:04:16.070532Z","shell.execute_reply.started":"2025-08-22T01:03:51.008120Z","shell.execute_reply":"2025-08-22T01:04:16.069773Z"}},"outputs":[{"name":"stderr","text":"2025-08-22 01:03:55.572801: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1755824635.790507      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1755824635.853746      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"id":"c7a874e877f9327d","cell_type":"markdown","source":"# Data Reading","metadata":{}},{"id":"22976ed543cf73cf","cell_type":"code","source":"train_file = '/kaggle/input/stanford-question-answering-dataset/train-v1.1.json'\ndev_file = '/kaggle/input/stanford-question-answering-dataset/dev-v1.1.json'\n\ndef load_prepare_data(file_path):\n    with open(file_path, 'r') as f:\n        data = json.load(f)\n\n    records = []\n    for article in data['data']:\n        for paragraph in article['paragraphs']:\n            context = paragraph['context']\n            for qa in paragraph['qas']:\n                question = qa['question']\n                answers = {\n                    \"text\": [ans['text'] for ans in qa['answers']],\n                    \"answer_start\": [ans['answer_start'] for ans in qa['answers']],\n                }\n                records.append({\n                    \"id\": qa[\"id\"],  # Ensure to use the ID if available\n                    \"title\": article[\"title\"],\n                    \"context\": context,\n                    \"question\": question,\n                    \"answers\": answers,\n                })\n    return records\n\n\ntrain_data = load_prepare_data(train_file)\ndev_data = load_prepare_data(dev_file)\n\n\ntrain_dataset = Dataset.from_pandas(pd.DataFrame(train_data))\nvalidation_dataset = Dataset.from_pandas(pd.DataFrame(dev_data))\n\nsquad = DatasetDict({\n    \"train\": train_dataset,\n    \"validation\": validation_dataset\n})","metadata":{"ExecuteTime":{"end_time":"2025-08-21T15:29:38.970583Z","start_time":"2025-08-21T15:29:37.916677Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T01:04:16.071418Z","iopub.execute_input":"2025-08-22T01:04:16.071957Z","iopub.status.idle":"2025-08-22T01:04:18.659628Z","shell.execute_reply.started":"2025-08-22T01:04:16.071939Z","shell.execute_reply":"2025-08-22T01:04:18.659034Z"}},"outputs":[],"execution_count":2},{"id":"62d08110-64bb-4b52-89a1-0e9b4e1e14ee","cell_type":"markdown","source":"# BERT Preprocessing & Training","metadata":{}},{"id":"5c4c7921cc4557e2","cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')","metadata":{"ExecuteTime":{"end_time":"2025-08-21T15:29:40.047544Z","start_time":"2025-08-21T15:29:39.772416Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T01:04:18.661045Z","iopub.execute_input":"2025-08-22T01:04:18.661306Z","iopub.status.idle":"2025-08-22T01:04:22.069306Z","shell.execute_reply.started":"2025-08-22T01:04:18.661288Z","shell.execute_reply":"2025-08-22T01:04:22.068639Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8005ea629e7b4548871a6a7717ac5586"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6256bb17f7b6446a8cfd6ca7f5ba1b81"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"550ff3c861144c5b85c146cc6ec05c5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26068d86231246d9805f479a8cbd6386"}},"metadata":{}}],"execution_count":3},{"id":"b0c01313406d3c23","cell_type":"code","source":"def preprocess_function(examples):\n    questions = [q.strip() for q in examples[\"question\"]]\n    inputs = tokenizer(\n        questions,\n        examples[\"context\"],\n        max_length=384,\n        truncation=\"only_second\",\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    offset_mapping = inputs.pop(\"offset_mapping\")\n    answers = examples[\"answers\"]\n    start_positions = []\n    end_positions = []\n\n    for i, offset in enumerate(offset_mapping):\n        answer = answers[i]\n        start_char = answer[\"answer_start\"][0]\n        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n        sequence_ids = inputs.sequence_ids(i)\n\n        # Find the start and end of the context\n        idx = 0\n        while sequence_ids[idx] != 1:\n            idx += 1\n        context_start = idx\n        while sequence_ids[idx] == 1:\n            idx += 1\n        context_end = idx - 1\n\n        # If the answer is not fully inside the context, label it (0, 0)\n        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n            start_positions.append(0)\n            end_positions.append(0)\n        else:\n            # Otherwise it's the start and end token positions\n            idx = context_start\n            while idx <= context_end and offset[idx][0] <= start_char:\n                idx += 1\n            start_positions.append(idx - 1)\n\n            idx = context_end\n            while idx >= context_start and offset[idx][1] >= end_char:\n                idx -= 1\n            end_positions.append(idx + 1)\n\n    inputs[\"start_positions\"] = start_positions\n    inputs[\"end_positions\"] = end_positions\n    return inputs\n\ntokenized_squad = squad.map(preprocess_function, batched=True, remove_columns=squad[\"train\"].column_names)","metadata":{"ExecuteTime":{"end_time":"2025-08-21T15:29:58.441141Z","start_time":"2025-08-21T15:29:40.069135Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T01:04:22.069977Z","iopub.execute_input":"2025-08-22T01:04:22.070191Z","iopub.status.idle":"2025-08-22T01:05:12.236438Z","shell.execute_reply.started":"2025-08-22T01:04:22.070174Z","shell.execute_reply":"2025-08-22T01:05:12.235844Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/87599 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5c83ab41d2e435ab5c17ad815b3dd3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10570 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f54ea732ce741a6a010bba83294901f"}},"metadata":{}}],"execution_count":4},{"id":"166b7b9b650b35f6","cell_type":"code","source":"from transformers import DefaultDataCollator\n\ndata_collator = DefaultDataCollator(return_tensors=\"tf\")","metadata":{"ExecuteTime":{"end_time":"2025-08-21T15:29:58.464866Z","start_time":"2025-08-21T15:29:58.458873Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T01:05:12.237119Z","iopub.execute_input":"2025-08-22T01:05:12.237615Z","iopub.status.idle":"2025-08-22T01:05:12.240918Z","shell.execute_reply.started":"2025-08-22T01:05:12.237597Z","shell.execute_reply":"2025-08-22T01:05:12.240323Z"}},"outputs":[],"execution_count":5},{"id":"da44a4d1b646d61e","cell_type":"code","source":"batch_size = 8\nnum_epochs = 2\ntotal_train_steps = (len(tokenized_squad[\"train\"]) // batch_size) * num_epochs\noptimizer, schedule = create_optimizer(\n    init_lr=2e-5,\n    num_warmup_steps=0,\n    num_train_steps=total_train_steps,\n)","metadata":{"ExecuteTime":{"end_time":"2025-08-21T15:29:58.573419Z","start_time":"2025-08-21T15:29:58.483419Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T01:05:12.241698Z","iopub.execute_input":"2025-08-22T01:05:12.241910Z","iopub.status.idle":"2025-08-22T01:05:13.690677Z","shell.execute_reply.started":"2025-08-22T01:05:12.241893Z","shell.execute_reply":"2025-08-22T01:05:13.690113Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1755824712.478774      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}],"execution_count":6},{"id":"11d734c6901928ec","cell_type":"code","source":"model = TFAutoModelForQuestionAnswering.from_pretrained(\"bert-base-uncased\")","metadata":{"ExecuteTime":{"end_time":"2025-08-21T15:30:02.348373Z","start_time":"2025-08-21T15:29:58.598486Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T01:05:13.691369Z","iopub.execute_input":"2025-08-22T01:05:13.691572Z","iopub.status.idle":"2025-08-22T01:05:18.858724Z","shell.execute_reply.started":"2025-08-22T01:05:13.691556Z","shell.execute_reply":"2025-08-22T01:05:18.857969Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2853d20fe52446e28f67909d8b2883ab"}},"metadata":{}},{"name":"stderr","text":"All PyTorch model weights were used when initializing TFBertForQuestionAnswering.\n\nSome weights or buffers of the TF 2.0 model TFBertForQuestionAnswering were not initialized from the PyTorch model and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":7},{"id":"8e80b16bac0f5c0f","cell_type":"code","source":"tf_train_set = model.prepare_tf_dataset(\n    tokenized_squad[\"train\"],\n    shuffle=True,\n    batch_size=16,\n    collate_fn=data_collator,\n)\n\ntf_validation_set = model.prepare_tf_dataset(\n    tokenized_squad[\"validation\"],\n    shuffle=False,\n    batch_size=16,\n    collate_fn=data_collator,\n)","metadata":{"ExecuteTime":{"end_time":"2025-08-21T15:43:53.407334Z","start_time":"2025-08-21T15:43:53.136304Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T01:05:18.859495Z","iopub.execute_input":"2025-08-22T01:05:18.859752Z","iopub.status.idle":"2025-08-22T01:05:19.281287Z","shell.execute_reply.started":"2025-08-22T01:05:18.859732Z","shell.execute_reply":"2025-08-22T01:05:19.280708Z"}},"outputs":[],"execution_count":8},{"id":"ed3d7a01904016d","cell_type":"code","source":"model.compile(optimizer=optimizer)","metadata":{"ExecuteTime":{"end_time":"2025-08-21T15:43:53.429824Z","start_time":"2025-08-21T15:43:53.413509Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T01:05:19.283168Z","iopub.execute_input":"2025-08-22T01:05:19.283384Z","iopub.status.idle":"2025-08-22T01:05:19.296644Z","shell.execute_reply.started":"2025-08-22T01:05:19.283367Z","shell.execute_reply":"2025-08-22T01:05:19.295915Z"}},"outputs":[],"execution_count":9},{"id":"e3624c2c88942ef8","cell_type":"code","source":"model.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=5)","metadata":{"ExecuteTime":{"start_time":"2025-08-21T15:43:53.484736Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T01:05:19.297412Z","iopub.execute_input":"2025-08-22T01:05:19.297665Z","iopub.status.idle":"2025-08-22T07:07:08.731902Z","shell.execute_reply.started":"2025-08-22T01:05:19.297643Z","shell.execute_reply":"2025-08-22T07:07:08.731121Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1755824752.570777     105 service.cc:148] XLA service 0x7c91f1e8b430 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1755824752.571274     105 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1755824752.642611     105 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1755824752.762812     105 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"5474/5474 [==============================] - 4380s 792ms/step - loss: 1.3145 - val_loss: 1.0156\nEpoch 2/5\n5474/5474 [==============================] - 4332s 791ms/step - loss: 0.8106 - val_loss: 0.9893\nEpoch 3/5\n5474/5474 [==============================] - 4333s 792ms/step - loss: 0.5842 - val_loss: 1.0456\nEpoch 4/5\n5474/5474 [==============================] - 4331s 791ms/step - loss: 0.4495 - val_loss: 1.1483\nEpoch 5/5\n5474/5474 [==============================] - 4334s 792ms/step - loss: 0.3996 - val_loss: 1.1483\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<tf_keras.src.callbacks.History at 0x7c9264e193d0>"},"metadata":{}}],"execution_count":10},{"id":"4a6d0a0cadbef33c","cell_type":"code","source":"model.save_pretrained('my_first_QA_model')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T07:07:08.732827Z","iopub.execute_input":"2025-08-22T07:07:08.733527Z","iopub.status.idle":"2025-08-22T07:07:10.068085Z","shell.execute_reply.started":"2025-08-22T07:07:08.733508Z","shell.execute_reply":"2025-08-22T07:07:10.067470Z"}},"outputs":[],"execution_count":11},{"id":"e3f7aa71-1f09-4bf9-a12c-269614e6f545","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}